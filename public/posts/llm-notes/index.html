<!doctype html>
<html
  lang="en"
  dir="ltr"
  class="scroll-smooth"
  data-default-appearance="light"
  data-auto-appearance="false"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
  
    <meta http-equiv="content-language" content="en">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="theme-color">

  
  
    <title>My LLM Cheatsheet: Concepts, Training, and Best Practices üß†‚ú® &middot; Home</title>
    <meta name="title" content="My LLM Cheatsheet: Concepts, Training, and Best Practices üß†‚ú® &middot; Home">
  

  
  
    <meta name="description" content="Business Data Analyst">
  
  
    <meta name="keywords" content="LLM,RAG,AI,Machine Learning,Transformers,LLM Engineering,AI Fundamentals,">
  
  
  
  <link rel="canonical" href="http://localhost:1313/posts/llm-notes/">
  

  
  
    <meta name="author" content="Fay√ßal Bessayah">
  
  
    
      
        
          <link href="https://github.com/fbessayah" rel="me">
        
      
    
      
        
          <link href="https://www.linkedin.com/in/fay%C3%A7al-bessayah-0a4b632b/" rel="me">
        
      
    
      
        
          <link href="https://medium.com/@fbessayah/" rel="me">
        
      
    
  

  
  <meta property="og:url" content="http://localhost:1313/posts/llm-notes/">
  <meta property="og:site_name" content="Home">
  <meta property="og:title" content="My LLM Cheatsheet: Concepts, Training, and Best Practices üß†‚ú®">
  <meta property="og:description" content="Large Language Models (LLMs) are everywhere now ‚Äî chatbots, copilots, search, coding, writing, and reasoning.
This is my personal LLM cheatsheet: concise notes I use to refresh core concepts, training ideas, and practical techniques without diving back into papers or long courses.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-12-22T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-12-22T00:00:00+00:00">
    <meta property="article:tag" content="LLM">
    <meta property="article:tag" content="RAG">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="Machine Learning">
    <meta property="article:tag" content="Transformers">
    <meta property="article:tag" content="LLM Engineering">
    <meta property="og:image" content="http://localhost:1313/posts/llm-notes/feature.jpg">

  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="http://localhost:1313/posts/llm-notes/feature.jpg">
  <meta name="twitter:title" content="My LLM Cheatsheet: Concepts, Training, and Best Practices üß†‚ú®">
  <meta name="twitter:description" content="Large Language Models (LLMs) are everywhere now ‚Äî chatbots, copilots, search, coding, writing, and reasoning.
This is my personal LLM cheatsheet: concise notes I use to refresh core concepts, training ideas, and practical techniques without diving back into papers or long courses.">

  
  
  
  
    
      
    
  
    
      
    
  
    
      
    
  
  
    
  

  
  
  
  
  
  

  

  
  
  
  
  
  
  
  
    
  
  
  <link
    type="text/css"
    rel="stylesheet"
    href="/css/main.bundle.min.c963a0b50da4af878f9f088c46dfb426c08ba12652bd5f1996b86e874139473f86569332221dad2684bf3dc6d6bab2baeac8a3d65ce1b83574d818df1a6c595c.css"
    integrity="sha512-yWOgtQ2kr4ePnwiMRt&#43;0JsCLoSZSvV8Zlrhuh0E5Rz&#43;GVpMyIh2tJoS/PcbWurK66sij1lzhuDV02BjfGmxZXA==">

  
  
  <script
    type="text/javascript"
    src="/js/appearance.min.6f41174b3a05b680820fe08cadbfa5fb7a7ca347b76a0955cdc68b9d8aca1ce24f0547e138cea33bcc7904d551a90afcb1cc7f2d9fe8557075d501419046c08c.js"
    integrity="sha512-b0EXSzoFtoCCD&#43;CMrb&#43;l&#43;3p8o0e3aglVzcaLnYrKHOJPBUfhOM6jO8x5BNVRqQr8scx/LZ/oVXB11QFBkEbAjA=="></script>
  
  
  
  
  
  
    
    <script src="/lib/zoom/zoom.min.umd.a527109b68c082a70f3697716dd72a9d5aa8b545cf800cecbbc7399f2ca6f6e0ce3e431f2062b48bbfa47c9ea42822714060bef309be073f49b9c0e30d318d7b.js" integrity="sha512-pScQm2jAgqcPNpdxbdcqnVqotUXPgAzsu8c5nyym9uDOPkMfIGK0i7&#43;kfJ6kKCJxQGC&#43;8wm&#43;Bz9JucDjDTGNew=="></script>
  

  
  
  
    
  
  
    
  
  
  
  
  
  
  
    
    <script
      defer
      type="text/javascript"
      id="script-bundle"
      src="/js/main.bundle.min.9df4fc14d50efcc9aa4cfc2b6f348e365f421f5ad491278f8f48c0360cf2f93f08882fda6da162d7ace8e5add57c2df4ac46bd3861306b1d4c452cd31f448d64.js"
      integrity="sha512-nfT8FNUO/MmqTPwrbzSONl9CH1rUkSePj0jANgzy&#43;T8IiC/abaFi16zo5a3VfC30rEa9OGEwax1MRSzTH0SNZA=="
      data-copy="Copy"
      data-copied="Copied"></script>
  

  
  

<script src="/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js" integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj&#43;KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script>


























  

  

  

  

  





  
  
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
  

  
  <script type="application/ld+json">
  [{
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Blog",
    "name": "My LLM Cheatsheet: Concepts, Training, and Best Practices üß†‚ú®",
    "headline": "My LLM Cheatsheet: Concepts, Training, and Best Practices üß†‚ú®",
    
    "abstract": "\u003cp\u003eLarge Language Models (LLMs) are everywhere now ‚Äî chatbots, copilots, search, coding, writing, and reasoning.\u003cbr\u003e\nThis is my \u003cstrong\u003epersonal LLM cheatsheet\u003c\/strong\u003e: concise notes I use to refresh core concepts, training ideas, and practical techniques without diving back into papers or long courses.\u003c\/p\u003e",
    "inLanguage": "en",
    "url" : "http:\/\/localhost:1313\/posts\/llm-notes\/",
    "author" : {
      "@type": "Person",
      "name": "Fay√ßal Bessayah"
    },
    "copyrightYear": "2025",
    "dateCreated": "2025-12-22T00:00:00\u002b00:00",
    "datePublished": "2025-12-22T00:00:00\u002b00:00",
    
    "dateModified": "2025-12-22T00:00:00\u002b00:00",
    
    "keywords": ["LLM","RAG","AI","Machine Learning","Transformers","LLM Engineering","AI Fundamentals"],
    
    "mainEntityOfPage": "true",
    "wordCount": "1026"
  }]
  </script>



  
  

  
  

  
  

  
  

  
  
</head>


















  
  
  <body class="flex flex-col h-screen m-auto leading-7 max-w-7xl px-6 sm:px-14 md:px-24 lg:px-32 text-lg bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600">
    <div id="the-top" class="absolute flex self-center">
      <a
        class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600"
        href="#main-content">
        <span class="font-bold text-primary-600 pe-2 dark:text-primary-400">&darr;</span>
        Skip to main content
      </a>
    </div>
    
    
      













<div
  class="main-menu flex items-center justify-between py-6 md:justify-start gap-x-3 pt-[2px] pr-2 md:pr-4 pb-[3px] pl-0">
  
  

  <div class="flex flex-1 items-center justify-between">
    <nav class="flex space-x-3">
      
        <a href="/" class="text-base font-medium">
          Home
        </a>
      
    </nav>
    
  <nav class="hidden md:flex items-center gap-x-5 md:ml-12 h-12">
    
      
        
  <a
  href="/posts/"
  
  class="flex items-center hover:text-primary-600 dark:hover:text-primary-400"
  aria-label="Blog"
  title="Blog">
  
  
    <p class="text-base font-medium">
      Blog
    </p>
  
</a>



      
    

    
  <div>
    <div class="cursor-pointer flex items-center nested-menu">
      <span class="me-1 text-lg">
        üá¨üáß EN
      </span>
    </div>
    <div class="absolute menuhide">
      <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
        <div class="flex flex-col space-y-3">
          
            
              
            
              
                <a href="/fr/" class="flex items-center">
                  <p
                    class="text-sm font-sm hover:text-primary-600 dark:hover:text-primary-400"
                    title="Fran√ßais">
                    üá´üá∑ FR
                  </p>
                </a>
              
            
          
        </div>
      </div>
    </div>
  </div>


    

    
      <button
        id="search-button"
        aria-label="Search"
        class="text-base hover:text-primary-600 dark:hover:text-primary-400"
        title="Search (/)">
        <span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span>
      </button>
    

    
      <div class=" flex items-center">
        <button
          id="appearance-switcher"
          aria-label="Dark mode switcher"
          type="button"
          class="text-base hover:text-primary-600 dark:hover:text-primary-400">
          <div class="flex items-center justify-center dark:hidden">
            <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>
</span>
          </div>
          <div class="items-center justify-center hidden dark:flex">
            <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>
</span>
          </div>
        </button>
      </div>
    
  </nav>

    
  <div class="flex md:hidden items-center gap-x-5 md:ml-12 h-12">
    <span></span>

    
  <div>
    <div class="cursor-pointer flex items-center nested-menu">
      <span class="me-1 text-lg">
        üá¨üáß EN
      </span>
    </div>
    <div class="absolute menuhide">
      <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
        <div class="flex flex-col space-y-3">
          
            
              
            
              
                <a href="/fr/" class="flex items-center">
                  <p
                    class="text-sm font-sm hover:text-primary-600 dark:hover:text-primary-400"
                    title="Fran√ßais">
                    üá´üá∑ FR
                  </p>
                </a>
              
            
          
        </div>
      </div>
    </div>
  </div>


    

    
      <button
        id="search-button-mobile"
        aria-label="Search"
        class="text-base hover:text-primary-600 dark:hover:text-primary-400"
        title="Search (/)">
        <span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span>
      </button>
    

    
      <button
        id="appearance-switcher-mobile"
        aria-label="Dark mode switcher"
        type="button"
        class="text-base hover:text-primary-600 dark:hover:text-primary-400 me-1">
        <div class="flex items-center justify-center dark:hidden">
          <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>
</span>
        </div>
        <div class="items-center justify-center hidden dark:flex">
          <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>
</span>
        </div>
      </button>
    
  </div>

  </div>
  
  <div class="-my-2 md:hidden">
    <div id="menu-button" class="block">
      
        <div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400">
          <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416C433.7 64 448 78.33 448 96C448 113.7 433.7 128 416 128H32C14.33 128 0 113.7 0 96zM0 256C0 238.3 14.33 224 32 224H416C433.7 224 448 238.3 448 256C448 273.7 433.7 288 416 288H32C14.33 288 0 273.7 0 256zM416 448H32C14.33 448 0 433.7 0 416C0 398.3 14.33 384 32 384H416C433.7 384 448 398.3 448 416C448 433.7 433.7 448 416 448z"/></svg>
</span>
        </div>
        <div
          id="menu-wrapper"
          class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50 pt-[5px]">
          <ul
            class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none text-end max-w-7xl">
            <li id="menu-close-button">
              <span
                class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400">
                <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>
</span>
              </span>
            </li>

            
              
  <li class="mt-1">
  <a
    href="/posts/"
    
    class="flex items-center hover:text-primary-600 dark:hover:text-primary-400"
    aria-label="Blog"
    title="Blog">
    
    
      <p class="text-bg font-bg">
        Blog
      </p>
    
  </a>
</li>



            

          </ul>
          
        </div>
      
    </div>
  </div>

</div>





    
    <div class="relative flex flex-col grow">
      <main id="main-content" class="grow">
        
  
  <article>
    
    

    
    <header id="single_header" class="mt-5 max-w-prose">
      
      <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
        My LLM Cheatsheet: Concepts, Training, and Best Practices üß†‚ú®
      </h1>
      <div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
        





  
  



  

  
  
  
    
  

  

  
    
  

  

  
    
  

  
    
  

  

  

  

  

  


  <div class="flex flex-row flex-wrap items-center">
    
    
      <time datetime="2025-12-22T00:00:00&#43;00:00">December 22, 2025</time><span class="px-2 text-primary-500">&middot;</span><span>1026 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">5 mins</span>
    

    
    
  </div>

  

  
  

  
  



      </div>
      
        
  
  
  
  
  
  

  

  
    
    
<div class="flex author">
  
    
    
      
    
    
      
      
        
      
      <img
        class="!mt-0 !mb-0 h-24 w-24 rounded-full me-4"
        width="96"
        height="96"
        alt="Fay√ßal Bessayah"
        src="/img/photo_profil_hu_5193ef8dc043a20c.jpeg"
        data-zoom-src="/img/photo_profil.jpeg">
    
  
  <div class="place-self-center">
    
      <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
        Author
      </div>
      <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
        Fay√ßal Bessayah
      </div>
    
    
      <div class="text-sm text-neutral-700 dark:text-neutral-400">I share my analyses, experiments, and discoveries about data</div>
    
    <div class="text-2xl sm:text-lg">
  <div class="flex flex-wrap text-neutral-400 dark:text-neutral-500">
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://github.com/fbessayah"
          target="_blank"
          aria-label="Github"
          title="Github"
          rel="me noopener noreferrer"
          ><span class="inline-block align-text-bottom"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a
        >
      
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://www.linkedin.com/in/fay%C3%A7al-bessayah-0a4b632b/"
          target="_blank"
          aria-label="Linkedin"
          title="Linkedin"
          rel="me noopener noreferrer"
          ><span class="inline-block align-text-bottom"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></span></a
        >
      
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://medium.com/@fbessayah/"
          target="_blank"
          aria-label="Medium"
          title="Medium"
          rel="me noopener noreferrer"
          ><span class="inline-block align-text-bottom"><span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><path fill="currentColor" d="M180.5,74.262C80.813,74.262,0,155.633,0,256S80.819,437.738,180.5,437.738,361,356.373,361,256,280.191,74.262,180.5,74.262Zm288.25,10.646c-49.845,0-90.245,76.619-90.245,171.095s40.406,171.1,90.251,171.1,90.251-76.619,90.251-171.1H559C559,161.5,518.6,84.908,468.752,84.908Zm139.506,17.821c-17.526,0-31.735,68.628-31.735,153.274s14.2,153.274,31.735,153.274S640,340.631,640,256C640,171.351,625.785,102.729,608.258,102.729Z"/></svg>
</span></span></a
        >
      
    
  </div>

</div>
  </div>
</div>

  

  

  
    <div class="mb-5"></div>
  

      
    </header>

    
    <section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row">
      
      
      
      
      


      <div class="min-w-0 min-h-0 max-w-fit">
        

        <div class="article-content max-w-prose mb-20">
          <p>Large Language Models (LLMs) are everywhere now ‚Äî chatbots, copilots, search, coding, writing, and reasoning.<br>
This is my <strong>personal LLM cheatsheet</strong>: concise notes I use to refresh core concepts, training ideas, and practical techniques without diving back into papers or long courses.</p>
<hr>

<h2 class="relative group">1. Core Concepts
    <div id="1-core-concepts" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#1-core-concepts" aria-label="Anchor">#</a>
    </span>
    
</h2>

<h3 class="relative group">What is an LLM?
    <div id="what-is-an-llm" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#what-is-an-llm" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>An <strong>LLM (Large Language Model)</strong> is a neural network trained on massive text corpora to <strong>predict the next token</strong>.</p>
<p>With enough scale, this simple objective unlocks:</p>
<ul>
<li>Text generation</li>
<li>Reasoning</li>
<li>Translation</li>
<li>Summarization</li>
<li>Q&amp;A</li>
</ul>
<p>By learning to predict the next word in sentences over billions of examples, LLMs implicitly learn grammar, facts, reasoning patterns, and even some world knowledge.</p>
<hr>

<h3 class="relative group">Tokenization
    <div id="tokenization" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#tokenization" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>LLMs don‚Äôt read text ‚Äî they read <strong>tokens</strong>.</p>
<p>Tokenization is how text becomes numeric input. Smaller tokens give flexibility but increase sequence length, while larger tokens are faster but less flexible.</p>
<ul>
<li>Text ‚Üí tokens ‚Üí numbers</li>
<li>Tokens can be words, subwords, or characters</li>
<li>Example:<br>
<code>cryptocurrency ‚Üí crypto + currency</code></li>
</ul>
<p><strong>Why it matters:</strong></p>
<ul>
<li>Handles rare / new words</li>
<li>Controls vocabulary size</li>
<li>Impacts cost (more tokens = more compute)</li>
</ul>
<hr>

<h3 class="relative group">Context Window
    <div id="context-window" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#context-window" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>The <strong>context window</strong> is the model‚Äôs working memory. LLMs can only ‚Äúsee‚Äù a limited number of tokens at a time. Anything beyond the window is ignored, so long documents may need special handling.</p>
<ul>
<li>Measured in tokens (4k, 8k, 32k, 128k‚Ä¶)</li>
<li>Bigger window = more context, better coherence</li>
<li>Trade-off: <strong>cost &amp; latency</strong></li>
</ul>
<hr>

<h2 class="relative group">2. Transformer Fundamentals
    <div id="2-transformer-fundamentals" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#2-transformer-fundamentals" aria-label="Anchor">#</a>
    </span>
    
</h2>

<h3 class="relative group">Attention (The Secret Sauce)
    <div id="attention-the-secret-sauce" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#attention-the-secret-sauce" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>Attention lets the model decide <strong>what matters most</strong> in a sequence. It allows the model to focus on relevant words regardless of their position, enabling it to capture complex relationships in language.</p>
<p>Instead of reading text left-to-right only, the model:</p>
<ul>
<li>Looks at all tokens</li>
<li>Assigns importance weights</li>
<li>Builds context dynamically</li>
</ul>
<p>This is why transformers scale so well.</p>
<hr>

<h3 class="relative group">Self-Attention Formula (High Level)
    <div id="self-attention-formula-high-level" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#self-attention-formula-high-level" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>Self-attention computes a weighted sum of all words in a sequence, where weights measure relevance to each word.</p>
<p>Attention(Q, K, V) = softmax(QK·µÄ / ‚àöd‚Çñ) ¬∑ V</p>
<ul>
<li><strong>Q</strong>: What I‚Äôm looking for</li>
<li><strong>K</strong>: What I have</li>
<li><strong>V</strong>: The actual information</li>
</ul>
<hr>

<h3 class="relative group">Multi-Head Attention
    <div id="multi-head-attention" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#multi-head-attention" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>Multi-head attention allows the model to capture multiple perspectives simultaneously, improving understanding of complex sentences.</p>
<ul>
<li>Each head focuses on different patterns:
<ul>
<li>Syntax</li>
<li>Semantics</li>
<li>Long-range dependencies</li>
</ul>
</li>
</ul>
<hr>

<h3 class="relative group">Positional Encoding
    <div id="positional-encoding" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#positional-encoding" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>Attention alone has <strong>no sense of order</strong>. Positional encodings give the model information about word order.</p>
<p>Positional encodings inject:</p>
<ul>
<li>Token position</li>
<li>Sequence structure</li>
</ul>
<p>Without them, word order wouldn‚Äôt matter.</p>
<hr>

<h2 class="relative group">3. Training Paradigms
    <div id="3-training-paradigms" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#3-training-paradigms" aria-label="Anchor">#</a>
    </span>
    
</h2>

<h3 class="relative group">Autoregressive vs Masked Models
    <div id="autoregressive-vs-masked-models" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#autoregressive-vs-masked-models" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p><strong>Autoregressive (GPT-style)</strong></p>
<ul>
<li>Predict next token</li>
<li>Best for generation</li>
</ul>
<p><strong>Masked (BERT-style)</strong></p>
<ul>
<li>Predict hidden tokens</li>
<li>Best for understanding &amp; classification</li>
</ul>
<p>Autoregressive models excel at producing coherent text, while masked models excel at understanding context for tasks like classification or QA.</p>
<hr>

<h3 class="relative group">Pretraining Objectives
    <div id="pretraining-objectives" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#pretraining-objectives" aria-label="Anchor">#</a>
    </span>
    
</h3>
<ul>
<li><strong>Next-token prediction</strong></li>
<li><strong>Masked Language Modeling (MLM)</strong></li>
<li><strong>Next Sentence Prediction (NSP)</strong> (less common now)</li>
</ul>
<p>These objectives define what the model learns during pretraining, shaping whether it is better at generating or understanding text.</p>
<hr>

<h3 class="relative group">Loss Function
    <div id="loss-function" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#loss-function" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p><strong>Cross-entropy loss</strong> measures how well the predicted probability distribution matches the true tokens. Lower loss = better predictions.</p>
<p>Most LLMs optimize <strong>cross-entropy loss</strong> by:</p>
<ul>
<li>Penalizing wrong token predictions</li>
<li>Encouraging probability mass on correct tokens</li>
</ul>
<hr>

<h2 class="relative group">4. Generation Controls (Very Practical)
    <div id="4-generation-controls-very-practical" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#4-generation-controls-very-practical" aria-label="Anchor">#</a>
    </span>
    
</h2>

<h3 class="relative group">Temperature
    <div id="temperature" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#temperature" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>Controls randomness:</p>
<ul>
<li><code>0.2</code> ‚Üí deterministic</li>
<li><code>0.7‚Äì0.9</code> ‚Üí balanced</li>
<li><code>&gt;1.0</code> ‚Üí creative / risky</li>
</ul>
<p>Temperature scales the probability distribution of the next token. Low temperature = safe predictions, high = more diverse output.</p>
<hr>

<h3 class="relative group">Top-K Sampling
    <div id="top-k-sampling" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#top-k-sampling" aria-label="Anchor">#</a>
    </span>
    
</h3>
<ul>
<li>Sample only from the top <code>K</code> tokens</li>
<li>Prevents weird low-probability outputs</li>
<li>Limits the choice to the most likely tokens, reducing nonsensical text while keeping some randomness.</li>
</ul>
<hr>

<h3 class="relative group">Top-P (Nucleus) Sampling
    <div id="top-p-nucleus-sampling" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#top-p-nucleus-sampling" aria-label="Anchor">#</a>
    </span>
    
</h3>
<ul>
<li>Sample from tokens whose cumulative probability ‚â• <code>p</code></li>
<li>More adaptive than Top-K</li>
<li>Dynamically chooses a subset of probable tokens so that rare but important words can still be selected.</li>
<li>Best choice for creative tasks</li>
</ul>
<hr>

<h3 class="relative group">Beam Search
    <div id="beam-search" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#beam-search" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>Beam search explores several paths at once, picking the most probable sequence, which improves fluency but reduces diversity.</p>
<ul>
<li>Keeps multiple candidate sequences</li>
<li>Improves coherence</li>
<li>Less creative, more ‚Äúsafe‚Äù</li>
</ul>
<hr>

<h2 class="relative group">5. Fine-Tuning &amp; Efficiency
    <div id="5-fine-tuning--efficiency" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#5-fine-tuning--efficiency" aria-label="Anchor">#</a>
    </span>
    
</h2>

<h3 class="relative group">Catastrophic Forgetting
    <div id="catastrophic-forgetting" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#catastrophic-forgetting" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>When fine-tuning overwrites prior knowledge.</p>
<p>Mitigations:</p>
<ul>
<li>Mix old + new data</li>
<li>Freeze most weights</li>
<li>Use adapters</li>
</ul>
<p>Without precautions, fine-tuning can erase the general knowledge learned during pretraining.</p>
<hr>

<h3 class="relative group">PEFT (Parameter-Efficient Fine-Tuning)
    <div id="peft-parameter-efficient-fine-tuning" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#peft-parameter-efficient-fine-tuning" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>PEFT methods let you adapt huge models to new tasks without retraining everything, saving resources.</p>
<p>Popular techniques:</p>
<ul>
<li><strong>LoRA</strong></li>
<li><strong>QLoRA</strong> (LoRA + quantization)</li>
</ul>
<p>Benefits:</p>
<ul>
<li>Lower memory usage</li>
<li>Cheaper training</li>
<li>Works on large models with limited hardware</li>
</ul>
<hr>

<h3 class="relative group">Model Distillation
    <div id="model-distillation" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#model-distillation" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>Train a small model to mimic a large one.</p>
<p>Distillation transfers knowledge from a big model to a smaller one, keeping most capabilities but reducing compute needs.</p>
<ul>
<li>Faster</li>
<li>Cheaper</li>
<li>Great for edge devices</li>
</ul>
<hr>

<h2 class="relative group">6. Retrieval &amp; Reasoning
    <div id="6-retrieval--reasoning" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#6-retrieval--reasoning" aria-label="Anchor">#</a>
    </span>
    
</h2>

<h3 class="relative group">RAG (Retrieval-Augmented Generation)
    <div id="rag-retrieval-augmented-generation" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#rag-retrieval-augmented-generation" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>LLMs don‚Äôt ‚Äúknow‚Äù facts ‚Äî they <strong>predict text</strong>.</p>
<p>RAG pipeline:</p>
<ol>
<li>Retrieve documents</li>
<li>Rank relevance</li>
<li>Generate using retrieved context</li>
</ol>
<p>This:</p>
<ul>
<li>Reduces hallucinations</li>
<li>Improves factual accuracy</li>
</ul>
<p>By combining LLMs with external knowledge, RAG ensures outputs are grounded in real data rather than just model memorization.</p>
<hr>

<h3 class="relative group">Chain-of-Thought (CoT)
    <div id="chain-of-thought-cot" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#chain-of-thought-cot" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>Encourages step-by-step reasoning.</p>
<p>Useful for:</p>
<ul>
<li>Math</li>
<li>Logic</li>
<li>Multi-step questions</li>
</ul>
<p>CoT prompts make the model ‚Äúthink out loud,‚Äù improving multi-step reasoning performance.</p>
<hr>

<h3 class="relative group">Zero-Shot &amp; Few-Shot Learning
    <div id="zero-shot--few-shot-learning" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#zero-shot--few-shot-learning" aria-label="Anchor">#</a>
    </span>
    
</h3>
<ul>
<li><strong>Zero-shot</strong>: Just instructions</li>
<li><strong>Few-shot</strong>: Add 2‚Äì5 examples</li>
</ul>
<p>Prompt quality often matters more than model size.</p>
<p>LLMs can perform tasks without explicit training, but giving examples usually boosts accuracy.</p>
<hr>

<h2 class="relative group">7. Scaling Tricks
    <div id="7-scaling-tricks" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#7-scaling-tricks" aria-label="Anchor">#</a>
    </span>
    
</h2>

<h3 class="relative group">Mixture of Experts (MoE)
    <div id="mixture-of-experts-moe" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#mixture-of-experts-moe" aria-label="Anchor">#</a>
    </span>
    
</h3>
<ul>
<li>Many expert sub-models</li>
<li>Only a few activate per input</li>
</ul>
<p>Result:</p>
<ul>
<li>Massive models</li>
<li>Lower inference cost</li>
</ul>
<p>MoE allows enormous models to exist without making every computation expensive by activating only relevant ‚Äúexperts‚Äù for each input.</p>
<hr>

<h3 class="relative group">Adaptive Softmax
    <div id="adaptive-softmax" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#adaptive-softmax" aria-label="Anchor">#</a>
    </span>
    
</h3>
<p>It speeds up prediction for frequent words while using fewer resources for rare ones.</p>
<ul>
<li>Optimizes large vocabularies</li>
<li>Faster training</li>
<li>Lower memory usage</li>
</ul>
<hr>

<h2 class="relative group">8. Challenges &amp; Limitations
    <div id="8-challenges--limitations" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#8-challenges--limitations" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>LLMs are powerful tools but come with technical, ethical, and operational challenges that must be managed.</p>
<ul>
<li>High compute cost</li>
<li>Bias from training data</li>
<li>Hallucinations</li>
<li>Limited interpretability</li>
<li>Privacy &amp; data leakage risks</li>
</ul>
<hr>

<h2 class="relative group">Final Thoughts
    <div id="final-thoughts" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none">
        <a class="text-primary-300 dark:text-neutral-700 !no-underline" href="#final-thoughts" aria-label="Anchor">#</a>
    </span>
    
</h2>
<p>This cheatsheet is <strong>not exhaustive</strong>, but it covers:</p>
<ul>
<li>How LLMs work</li>
<li>How they‚Äôre trained</li>
<li>How to control them</li>
<li>How to deploy them wisely</li>
</ul>
<p>Mastering these concepts is often enough to reason effectively about LLM behavior, limitations, and trade-offs in real systems.</p>
          
          
          
        </div>
        
        

        

        

      </div>

      
      
        
        
          
          
        
        
        
        <script
          type="text/javascript"
          src="/js/page.min.54b6f4371722649edbe871e431d8670d670878c22be8f36e229fe53cc9b786fe25a834def5e6de621f7a3e37b72bc8cd73839aa5ed907ed6cbd45cd3e1b0fa20.js"
          integrity="sha512-VLb0NxciZJ7b6HHkMdhnDWcIeMIr6PNuIp/lPMm3hv4lqDTe9ebeYh96Pje3K8jNc4Oape2QftbL1FzT4bD6IA=="
          data-oid="views_posts/llm-notes/index.md"
          data-oid-likes="likes_posts/llm-notes/index.md"></script>
      
    </section>

    
    <footer class="pt-8 max-w-prose print:hidden">
      
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600">
      <div class="flex justify-between pt-3">
        <span class="flex flex-col">
          
            <a
              class="flex text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
              href="/posts/loid-de-benford/">
              <span class="leading-6">
                <span class="inline-block rtl:rotate-180">&larr;</span>&ensp;Benford's Law: The Anti-Fraud Tool Most Analysts Never Use
              </span>
            </a>
            
              <span class="ms-6 mt-1 text-xs text-neutral-500 dark:text-neutral-400">
                <time datetime="2025-12-13T00:00:00&#43;00:00">December 13, 2025</time>
              </span>
            
          
        </span>
        <span class="flex flex-col items-end">
          
            <a
              class="flex text-right text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
              href="/posts/business-problems/">
              <span class="leading-6">
                The Business Problems Every Data Analyst Needs to Master&ensp;<span class="inline-block rtl:rotate-180">&rarr;</span>
              </span>
            </a>
            
              <span class="me-6 mt-1 text-xs text-neutral-500 dark:text-neutral-400">
                <time datetime="2025-12-25T00:00:00&#43;00:00">December 25, 2025</time>
              </span>
            
          
        </span>
      </div>
    </div>
  


      
    </footer>
  </article>

        


  






<div
  id="scroll-to-top"
  class="fixed bottom-6 end-6 z-50 transform translate-y-4 opacity-0 duration-200">
  <a
    href="#the-top"
    class="pointer-events-auto flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
    aria-label="Scroll to top"
    title="Scroll to top">
    &uarr;
  </a>
</div>

      </main><footer id="site-footer" class="py-10 print:hidden">
  
  
    
  
  <div class="flex items-center justify-between">
    
    
      <p class="text-sm text-neutral-500 dark:text-neutral-400">
          &copy;
          2026
          Fay√ßal Bessayah
      </p>
    

    
    
      <p class="text-xs text-neutral-500 dark:text-neutral-400">
        
        
        Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
          href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
          href="https://blowfish.page/" target="_blank" rel="noopener noreferrer">Blowfish</a>
      </p>
    
  </div>
  
    <script>
      mediumZoom(document.querySelectorAll("img:not(.nozoom)"), {
        margin: 24,
        background: "rgba(0,0,0,0.5)",
        scrollOffset: 0,
      });
    </script>
  
  
  
  <script
    type="text/javascript"
    src="/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js"
    integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh&#43;sCQ0E53ghYrxgYqw&#43;0GCRyIEpA=="></script>
  
  
</footer>
<div
  id="search-wrapper"
  class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh] z-500"
  data-url="http://localhost:1313/">
  <div
    id="search-modal"
    class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800">
    <header class="relative z-10 flex items-center justify-between flex-none px-2">
      <form class="flex items-center flex-auto min-w-0">
        <div class="flex items-center justify-center w-8 h-8 text-neutral-400">
          <span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span>
        </div>
        <input
          type="search"
          id="search-query"
          class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0">
      </form>
      <button
        id="close-search-button"
        class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)">
        <span class="relative block icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>
</span>
      </button>
    </header>
    <section class="flex-auto px-2 overflow-auto">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

    </div>
  </body>
  
</html>
